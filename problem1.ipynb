{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CooperUSA/CS492_ItSS/blob/main/problem1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSbcIdIi0on5"
      },
      "source": [
        "# **Signal Processing Basics**\n",
        "\n",
        "---\n",
        "\n",
        "## **Objective**\n",
        "This exercise aims to understand the basic signal processing techniques, including Fourier Transform, peak detection, Short-Time Fourier Transform (STFT), and z-score normalization.\n",
        "\n",
        "---\n",
        "\n",
        "## **Grading**\n",
        "- **Total Points: 30 points**\n",
        "    - Exercise 1-1: 8 points\n",
        "    - Exercise 1-2: 11 points\n",
        "    - Exercise 1-3: 11 points\n",
        "\n",
        "---\n",
        "\n",
        "## **Deliverables**\n",
        "- A **Jupyter Notebook** (team{team_number}_p1.ipynb) including complete function implementations and answers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGZhRXwI0on7"
      },
      "source": [
        "### 0. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3HPYHGF0on8",
        "outputId": "097ccf7f-d83c-4d12-b16c-6ce2dfdeaaa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1XxW3R1krLKAYHTbvln3mknSja05r2ulk\n",
            "To: /content/0-1.wav\n",
            "100% 320k/320k [00:00<00:00, 105MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Wk0E-fjXTccim6BthESC8C3-I13tERgo\n",
            "To: /content/0-2.wav\n",
            "100% 320k/320k [00:00<00:00, 99.2MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1TnlzxC8FX_hfywWIZWbbQTOZgNBCh9h4\n",
            "To: /content/0-3.csv\n",
            "100% 6.32M/6.32M [00:00<00:00, 26.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "########### Do Not Modify ###############\n",
        "!gdown https://drive.google.com/uc?id=1XxW3R1krLKAYHTbvln3mknSja05r2ulk\n",
        "!gdown https://drive.google.com/uc?id=1Wk0E-fjXTccim6BthESC8C3-I13tERgo\n",
        "!gdown https://drive.google.com/uc?id=1TnlzxC8FX_hfywWIZWbbQTOZgNBCh9h4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yO2XzYJu0on8"
      },
      "outputs": [],
      "source": [
        "########### Do Not Modify ###############\n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import wavfile\n",
        "from scipy.fft import fft, fftfreq\n",
        "from scipy.signal import find_peaks, spectrogram\n",
        "from scipy.io.wavfile import write\n",
        "########### Use Only Imported Libraries ###########"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUun08NN0on9"
      },
      "source": [
        "### 1. Warm-up: Signal Processing Basics\n",
        "\n",
        "### 1-1. Finding Peak Frequencies (8 Points)\n",
        "- **Task**:\n",
        "\n",
        "    1. Performs a Fast Fourier Transform (FFT) to convert the signal from the time domain into the frequency domain. (3 Point)\n",
        "    2. Identifies and lists the <span style=\"color:red\">*three*</span> dominant frequencies present in the audio signal. (5 Point)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SsWwkAgX0on9"
      },
      "outputs": [],
      "source": [
        "def apply_fft(sample_rate, audio_signal):\n",
        "    \"\"\"\n",
        "    Applies a Fast Fourier Transform (FFT) to the given signal. (3 point)\n",
        "\n",
        "    Input:\n",
        "        sample_rate (numpy.ndarray): Amplitude spectrum of the positive frequencies.\n",
        "        audio_signal (numpy.ndarray): Frequency bins corresponding to the amplitude spectrum.\n",
        "\n",
        "    Output:\n",
        "        freq_audio_signal_positive (numpy.ndarray): Amplitude spectrum of the positive frequencies.\n",
        "        freq_bins_positive (numpy.ndarray): Frequency bins corresponding to the amplitude spectrum.\n",
        "    \"\"\"\n",
        "\n",
        "    ## implement your code\n",
        "\n",
        "\n",
        "    return freq_audio_signal_positive, freq_bins_positive\n",
        "\n",
        "def find_dominant_frequencies(freq_audio_signal, freq_bins):\n",
        "    \"\"\"\n",
        "    Identifies and prints the three dominant frequencies from the frequency spectrum. (5 point)\n",
        "\n",
        "    Input:\n",
        "        freq_audio_signal (numpy.ndarray): Amplitude spectrum of the positive frequencies.\n",
        "        freq_bins (numpy.ndarray): Frequency bins corresponding to the amplitude spectrum.\n",
        "    Output:\n",
        "        None. Prints the three dominant frequencies (in Hz) with the highest amplitudes.\n",
        "    \"\"\"\n",
        "\n",
        "    ## implement your code\n",
        "\n",
        "def plot_signal(sample_rate, audio_signal):\n",
        "    plt.figure(figsize=(20,5))\n",
        "    plt.plot(audio_signal[:int(sample_rate*0.1)]) # plot signals for 0.1 second\n",
        "    plt.title('Audio Signal')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.show()\n",
        "\n",
        "def plot_frequency_spectrum(freq_audio_signal, freq_bins):\n",
        "    plt.figure(figsize=(20,5))\n",
        "    plt.plot(freq_bins, freq_audio_signal)\n",
        "    plt.title('Frequency Spectrum')\n",
        "    plt.xlabel('Frequency (Hz)')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "#### Do not modify ####\n",
        "sample_rate, audio_signal = wavfile.read(\"0-1.wav\")\n",
        "yf, xf = apply_fft(sample_rate, audio_signal)\n",
        "find_dominant_frequencies(yf, xf)\n",
        "\n",
        "plot_signal(sample_rate, audio_signal)\n",
        "plot_frequency_spectrum(yf, xf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6ulKit20on9"
      },
      "source": [
        "### 1-2. Understanding Short-Time Fourier Transform (STFT) (11 Point)\n",
        "- **Task**:\n",
        "\n",
        "    1. Visualizes the given signal using spectrogram with clearly labeled axes. (4 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNTP2iuH0on-"
      },
      "outputs": [],
      "source": [
        "def compute_and_plot_spectrogram(sample_rate, audio_signal):\n",
        "    \"\"\"\n",
        "    Plot a spectrogram using scipy.signal.spectrogram, specifying the \"nperseg\" and \"noverlap\" parameters. (4 point)\n",
        "\n",
        "    Input:\n",
        "        sample_rate (numpy.ndarray): Amplitude spectrum of the positive frequencies.\n",
        "        audio_signal (numpy.ndarray): Frequency bins corresponding to the amplitude spectrum.\n",
        "    Output:\n",
        "        None. Plots spectrogram.\n",
        "    \"\"\"\n",
        "    ## implement your code below\n",
        "\n",
        "    # Plot a spectrogram using scipy.signal.spectrogram, specifying the \"nperseg\" and \"noverlap\" parameters\n",
        "\n",
        "#### Do not modify ####\n",
        "sample_rate, audio_signal = wavfile.read('0-2.wav')\n",
        "compute_and_plot_spectrogram(sample_rate, audio_signal)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLJtXvZ_0on-"
      },
      "source": [
        "---\n",
        "#### Q1. What is the difference between Fourier Transform and Short-Time Fourier Transform? (3 points)\n",
        "<span style=\"color:red\">**Write your answer below:**</span>\n",
        "\n",
        "[Your Answer]\n",
        "\n",
        "---\n",
        "#### Q2. Explain how changing the window size and overlap percentage impacts the spectrogram obtained from Short-Time Fourier Transform (STFT). (4 points)\n",
        "<span style=\"color:red\">**Write your answer below:**</span>\n",
        "\n",
        "[Your Answer]\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BS0Rv17P0on-"
      },
      "source": [
        "### 1-3. Eavesdropping Alice using IMU (11 points)\n",
        "Mallory, a friend who lives in the next room to Alice, installed an IMU on the wall facing Alice’s room in order to steal Alice’s information.\n",
        "\n",
        "- **Task** - Perform appropriate processing to recover Alice's voice from 3-DOF IMU data.  (8 points)\n",
        "    1. Read IMU data. (3 points)\n",
        "    2. Apply z-score normallization to raw IMU data and convert them into audio signals. (5 points)\n",
        "\n",
        "- **Specification:**\n",
        "    - The sampling rate of the collected IMU data is 8 kHz.\n",
        "    - IMU data is saved as a csv file, where each column indicates [row_number], [timestamp], [x_axis_data], [y_axis_data], [z_axis_data], respectively"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "niVqR3aR0on-"
      },
      "outputs": [],
      "source": [
        "def read_data(file_path):\n",
        "    \"\"\"\n",
        "    Read IMU csv data. (3 point)\n",
        "\n",
        "    Input:\n",
        "        file_path (str): path of the file\n",
        "    Output:\n",
        "        acc_x_array (numpy.ndarray): numpy array of x-axis acceleration data\n",
        "        acc_y_array (numpy.ndarray): numpy array of y-axis acceleration data\n",
        "        acc_z_array (numpy.ndarray): numpy array of z-axis acceleration data\n",
        "    \"\"\"\n",
        "    # implment your code below\n",
        "\n",
        "    return acc_x_array, acc_y_array, acc_z_array\n",
        "\n",
        "def convert_imu_to_wav(raw_acc):\n",
        "    \"\"\"\n",
        "    Convert IMU data to audio signal. (5 points)\n",
        "\n",
        "    Input:\n",
        "        raw_acc (numpy.ndarray): numpy array of raw acceleration data\n",
        "    Output:\n",
        "        x_audio (numpy.ndarray): numpy array of audio signal\n",
        "    \"\"\"\n",
        "    # implment your code below\n",
        "\n",
        "    return x_audio\n",
        "\n",
        "#### Do not modify ####\n",
        "file_path = '0-3.csv'\n",
        "acc_x_array, acc_y_array, acc_z_array = read_data(file_path)\n",
        "acc_x_normalized = convert_imu_to_wav(acc_x_array)\n",
        "acc_y_normalized = convert_imu_to_wav(acc_y_array)\n",
        "acc_z_normalized = convert_imu_to_wav(acc_z_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15HOQMCp0on-"
      },
      "outputs": [],
      "source": [
        "#### Do not modify ####\n",
        "!mkdir ./result\n",
        "save_folder = 'result/'\n",
        "\n",
        "# Save acc_x_array as a WAV file\n",
        "write(save_folder + 'acc_x.wav', 8000, acc_x_normalized)\n",
        "write(save_folder + 'acc_y.wav', 8000, acc_y_normalized)\n",
        "write(save_folder + 'acc_z.wav', 8000, acc_z_normalized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLl0dpnR0on_"
      },
      "source": [
        "---\n",
        "#### Q3. Explain why normalization is essential to convert IMU data to audio signals. (3 points)\n",
        "<span style=\"color:red\">**Write your answer below:**</span>\n",
        "\n",
        "[Your Answer]\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "watchtag",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}